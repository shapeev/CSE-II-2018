{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE-II course, Skoltech, Term 4, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Set 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Methods\n",
    "\n",
    "Consider a problem of solving\n",
    "\\\\[\n",
    "\\begin{align*}\n",
    "-\\Delta u &= f, \\\\\n",
    "u|_\\Gamma &= 0.\n",
    "\\end{align*}\n",
    "\\\\]\n",
    "by a spectral method, where $\\Omega = [0,1]^2$ is a unit square and $\\Gamma=\\partial\\Omega$.\n",
    "\n",
    "In a spectral method you will be working with a representation of the solution in the form\n",
    "$$\n",
    "u(x,y) = \\sum_{i=1}^N \\sum_{j=1}^N \\hat{u}_{i,j} \\sin(\\pi i x) \\sin(\\pi j y),\n",
    "$$\n",
    "where $\\hat{u}^N$ is just an $N\\times N$ array.\n",
    "\n",
    "Knowing $u(x,y)$, it is often practically not possible to compute $\\hat{u}_{i,j}$ exactly. Hence one needs to use the [Discrete Sine Transform](http://docs.scipy.org/doc/scipy-dev/reference/tutorial/fftpack.html#discrete-sine-transforms) (DST).\n",
    "The python's <tt>dst</tt> computes a one-dimensional DST, but we need a two-dimensional (2D) DST, which we compute in the following way:\n",
    "    \n",
    "* Compute values $u(x,y)$ for $N^2$ points inside the domain $(x,y) = (h k, h \\ell)$, $1\\leq k,\\ell \\leq N$, $h = 1/(N+1)$.\n",
    "\n",
    "* Apply <tt>dst</tt> to each line in this array. This way you will be computing a \"partial\" 2D DST\n",
    "$$\n",
    "u(x,y) = \\sum_{j=1}^N \\tilde{u}_{j}(x) \\sin(\\pi j y),\n",
    "$$\n",
    "\n",
    "* Apply <tt>dst</tt> to each column in the resulting array. This way you will be computing a full 2D DST.\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 (Spectral Methods) (60pt)\n",
    "\n",
    "* Part (a)\n",
    "    - Take $u^0(x,y) = \\sin(\\pi x) \\sin(\\pi y)$ and compute $f = -\\Delta u^0$. \n",
    "    - **(7pt)** Calculate, explicitly, the coefficients $\\hat{f}_{i,j}$ in \n",
    "    $$\n",
    "    f(x,y) = \\sum_{i=1}^N \\sum_{j=1}^N \\hat{f}_{i,j} \\sin(\\pi i x) \\sin(\\pi j y).\n",
    "    $$\n",
    "    Then, using values of $f$ at $N^2$ points, calculate the coefficients $\\hat{f}^{N}_{i,j}$ by the procedure outlined above.\n",
    "    (Here $\\hat{f}$ is an \"infinite array\" that you will compute explicitly, while $\\hat{f}^N$ will be an NxN array that you will compute using python.)\n",
    "    Compare $\\hat{f}$ and $\\hat{f}^N$.\n",
    "    - In this case, obviously, a solution to the problem is $u=u_0$, but let us now pretend we do not know it.\n",
    "\n",
    "    - **(6pt)** Compute the coefficients $\\hat{u}^N$ from $\\hat{f}^N$ found in part (a).\n",
    "\n",
    "    - **(7pt)** We will estimate the error between the two solutions in the following way. We will take $N^2$ points in our domain, of the form $(h k, h \\ell)$, same as before. We will then be interested in\n",
    "    $$\n",
    "    {\\rm err}_N = \\max_{1\\leq k,\\ell\\leq N} |u^N(h k, h \\ell) - u^0(h k, h \\ell)|\n",
    "    $$\n",
    "    which we call an error of the solution. Calculate the error of your solution for a number of values of $N$. Explain your results\n",
    "\n",
    "* Part (b)\n",
    "    - Let us now take something a little more complicated,\n",
    "    $$\n",
    "    u^0(x,y) = \\sin(\\pi x^2) \\sin(\\pi y^2),\n",
    "    \\qquad\\text{and}\\qquad\n",
    "    f = -\\Delta u_0,\n",
    "    $$\n",
    "    - You cannot compute the coefficients $\\hat{f}$ explicitly, so you'll have to live with only $\\hat{f}^N$.\n",
    "    - **(7pt)** Compute $u^N$, the error ${\\rm err}_N$, and report the error for different values of $N$. Would you say the error decays fast as $N$ increases?\n",
    "    - Suppose that the spectral method has an order of convergence, in other words the error behaves like ${\\rm err}_N = C N^{-\\rm ord}$ and you need to find ${\\rm ord}$.\n",
    "        -  **(7pt)** Derive the formula\n",
    "        $$\n",
    "        {\\rm ord}_N = \\frac{\\ln({\\rm err}_N)-\\ln({\\rm err}_{2N})}{\\ln(2)}\n",
    "        $$\n",
    "        -  **(6pt)** Hence compute ${\\rm ord}_N$ for $N=1,\\ldots,20$ and comment on your results. (You should start with taking each value of $N$ between 1 and 20 to understand the behavior, but you don't need to present all these numbers in your report, as long as you can illustrate the right behavior.)\n",
    "\n",
    "* Part (c)\n",
    "    - Let us now play a \"fair game\": take\n",
    "    $$\n",
    "    f(x,y) = 1.\n",
    "    $$\n",
    "    We then do not know the solution.\n",
    "    - Use your code from part (b) to compute $\\hat{f}^N$, and $\\hat{u}^N$.\n",
    "    - **(5pt)** Instead of the exact error we have to use the error estimate\n",
    "    $$\n",
    "    {\\rm errest}_N = \\max_{1\\leq k,\\ell\\leq N} |u^N(h k, h \\ell) - u^{2N+1}(h k, h \\ell)|\n",
    "    $$\n",
    "    (Why did we take $2N+1$ instead $2N$?)\n",
    "    Report the values of ${\\rm errest}_N$ for a sequence of values of $N$.\n",
    "    \n",
    "    -  **(5pt)** Hence compute ${\\rm errest}_N$ for a sequence of $N$ and comment on your results.\n",
    "    -  **(5pt)** Finally, using the same formula (but with ${\\rm errest}$),\n",
    "    $$\n",
    "    {\\rm ord}_N = \\frac{\\ln({\\rm errest}_N)-\\ln({\\rm errest}_{2N})}{\\ln(2)}\n",
    "    $$\n",
    "    compute ${\\rm ord}_N$ for a squence of values of $N$. Comment on your results. \n",
    "*  **(5pt)** Compare the behavior for ${\\rm err}$, ${\\rm errest}$, and ${\\rm ord}$ for parts (b) and (c). What is the main reason for the qualitative difference in the speed of convergence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Integral Equations\n",
    "\n",
    "Wave phenomena play a very important role in many aspects of physics of our world, like acoustics, radio and optical telecommunications and take a major role in many devices, from MRI to nanooptical systems. Engineers from many fields need to be able to model them properly. The basic equations for those phenomena are different but, in case of time-harmonic solutions, they all become equivalent to scalar or vector Helmholtz equations.\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla^2 u(\\mathbf{r}) + k_0^2\\epsilon_r(\\mathbf{r})u(\\mathbf{r}) = \\rho(\\mathbf{r})\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\nabla \\times \\nabla \\times \\vec{E}(\\mathbf{r}) + \\epsilon_r(\\mathbf{r}) \\mu_r(\\mathbf{r}) k_0^2 \\vec{E}(\\mathbf{r}) = \\vec{J}(\\mathbf{r})\n",
    "\\end{equation}\n",
    "where $k_0 = \\frac{2 \\pi }{\\lambda_0} = \\frac{\\omega}{c}$, $\\lambda_0$  is the wavelength of free space, $\\omega$ is the angular frequency in radians per second, $c$  is the speed of light (or air depending on the problem), $\\epsilon_r$  is the relative dielectric permittivity, $\\mu_r$ is the relative magnetic permeability, $\\vec{E}(\\mathbf{r})$ is the strength of the electric Ô¨Åeld, $\\vec{J}(\\mathbf{r})$  is the excitation and $\\mathbf{r}=(x,y,z)$ is the the observation point.\n",
    "\\par\n",
    "For the current problem we will study infinite translational symmetry along one of the axis $\\hat{z}$ because the equations become two-dimensional therefore the problem is simplified (2D-VIE). If we consider the source as a dipole in the axis $\\hat{z}$ the equation becomes scalar and only the $E_z(\\mathbf{r})$ component is non-zero. Furthermore, the material properties are not magnetic ($\\mu_r(\\mathbf{r}) = 1$) and the final PDE equation becomes:\n",
    "$$\n",
    "\\nabla^2 E_z(\\mathbf{r}) + k_0^2\\epsilon_r(\\mathbf{r})E_z(\\mathbf{r}) = J_z(\\mathbf{r}), \\quad \\mathbf{r} \\in \\Omega, \\quad \\Omega = [-1,1] \\times [-1,1]\n",
    "$$\n",
    "This equation according to the \\textit{Surface} or \\textit{Volume Equivalence Principle} can be formulated as the following integral equation.\n",
    "$$\n",
    "E_z(\\mathbf{r}) + k_0^2 \\int (\\epsilon_r(\\mathbf{r})-1)E_z(\\mathbf{r}') G(|\\mathbf{r}-\\mathbf{r}'|) d\\mathbf{r}' = f(\\mathbf{r})\n",
    "$$\n",
    "where\n",
    "$$\n",
    "G(|\\mathbf{r}-\\mathbf{r}'|) = \\frac{\\mathfrak{i}}{4} H_0^{(2)}(|\\mathbf{r}-\\mathbf{r}'|)\n",
    "$$\n",
    "and as a source we can use a plane wave\n",
    "$$\n",
    "f(\\mathbf{r}) = e^{\\mathfrak{i} k_0 \\frac{\\sqrt{2}}{2}(x+y)}\n",
    "$$\n",
    "where $H_0^{(2)}$ is the second kind Hankel functon of zero order. Since we are dealing with a square domain, we can consider a uniform $N \\times N$ grid. To solve the equation we will apply the locally corrected Nystrom method. To simplify the problem the integration of Green function is given to you as\n",
    "$$\n",
    "G_{ij} = \\frac{\\mathfrak{i} h^2}{4} H_0^{(2)}(k_0 |\\mathbf{r}_i^{\\text{edge}} - \\mathbf{r}_j^{\\text{center}}|)\n",
    "$$\n",
    "By doing the integration like that, we avoid dealing with singular integrals.\n",
    "\n",
    "### Problem 2 (Integral Equations) (50pt)\n",
    "\n",
    " - Consider $N = 100$ and $\\lambda=0.5$.\n",
    "\n",
    " - **(10pt)** Prove that the form of the matrix after the application of Nystrom method will be: $A = I + k_0^2 G diag(\\epsilon_r-1)$. $I$ is the identity matrix, $G$ is the Green function matrix and $diag(\\epsilon_r-1)$ is a diagonal matrix with elements the appropriate relative dielectric permittivities $(-1)$.\n",
    "\n",
    " - **(20pt)** We want you to simulate the following \\textbf{Law of Reflection}. Consider a plasma mirror with $\\epsilon_r = -50$ for $x \\leq -0.75$ and $\\epsilon_r = 1$ otherwise (as in Figure 1). It is impossible to do it with a direct solver like LU decomposition since the required memory is prohibitive. You will have to use an iterative solver like GMRES (hint: use a Linear Operator) and exploit the BT-TB property of the Green function matrix. Describe the steps that you used in order to implement the accelerated matrix-vector product and plot the real part of the solution as an image like in Figure 2 (remember to use a colorbar).\n",
    " \n",
    " <img src=\"img/wall.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    " \n",
    " <img src=\"img/expected.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    " \n",
    "\n",
    " - **(10pt)** Change the $N$ to $50,200,300,400$. Plot the real part of the solutions for all cases and mention any changes in them.\n",
    "\n",
    " - **(10pt)** Implement a frequency sweep. Choose $\\lambda = 0.3,0.5,0.7,0.9$ and run the simulation for $N=50,100$. Plot the relative residual of the iterative solver in one figure for all the cases (use different colors!). What you can observe from your results? What is happening to the  convergence rate as long as we increase the operating frequency?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
